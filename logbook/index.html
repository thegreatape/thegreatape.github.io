<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Logbook &#8211; Duct Tape and Turing Machines</title>
<meta name="description" content="">
<meta name="keywords" content="">
<!-- Twitter Cards -->
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://localhost:4000/images/birds.jpg">
<meta name="twitter:title" content="Logbook">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@thegreatape">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Logbook">
<meta property="og:description" content="Duct Tape and Turing Machines">
<meta property="og:url" content="http://localhost:4000/logbook/">
<meta property="og:site_name" content="Duct Tape and Turing Machines">





<link rel="canonical" href="http://localhost:4000/logbook/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Duct Tape and Turing Machines Feed">


<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- Google Webfonts -->
<link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700|PT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>
<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.min.css">

<!--[if (lt IE 9) & (!IEMobile)]>
<link rel="stylesheet" href="http://localhost:4000/assets/css/ie.min.css">
<![endif]-->

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="articles" itemscope itemtype="http://schema.org/WebPage">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" itemscope itemtype="http://schema.org/SiteNavigationElement">
		    <ul>
		        
				<li><a href="http://localhost:4000/" >Articles</a></li>
		        
				<li><a href="http://localhost:4000/logbook" >Logbook</a></li>
		        
				<li><a href="http://localhost:4000/code" >Code</a></li>
		        
		        <li><i class="icon-feed"></i> <a href="http://localhost:4000/feed.xml" title="Atom/RSS feed">Feed</a>
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div class="article-author-top">
  <img src="http://localhost:4000/images/bio-photo.png" class="bio-photo" alt="Thomas Mayfield bio photo"></a>
<div class="bio-content">
  <h3>Thomas Mayfield</h3>
  <p>Polyglot programmer who loves the weird beautiful chaos of humans building software together. Fitness nerd. Southern kid living in Massachusetts.</p>
  <div class="social-icons">
    <a href="http://twitter.com/thegreatape" class="author-social" target="_blank"><i class="icon-twitter"></i> Twitter</a>
    
    
    
    
    <a href="http://github.com/thegreatape" class="author-social" target="_blank"><i class="icon-github"></i> Github</a>
    
    
  </div>
</div>

</div>

<div id="log-index" itemprop="mainContentOfPage" itemscope itemtype="http://schema.org/Blog">
  
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-05-25-interlude-furball/" rel="bookmark" title="Interlude - Furball"> 
          <span class="post-date">May 25, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>First, I’d like to introduce Ripley, one of the reasons my attention is a little scarce at the moment:</p>

<p><img src="/images/ripley.png" alt="Ripley" /></p>

<p>A nine-week old puppy is a joyous thing, and will happily hoover up every spare second you have.</p>

<p>Focused time for learning and study will resume probably around the time this little furball starts sleeping through the night without pee breaks. But even before we adopted her, it was pretty clear at this point that my goal of hitting a once-a-week writeup on things I’m learning isn’t going to happen. I do think striving for that cadence has still proven a push in the right direction. I’m going to continue tacking towards that goal even if the year-end average is probably going to come out lower than I hoped.</p>

<p>A few reflections from the last few weeks:</p>

<p>I’ve been leaning on <a href="https://habitica.com/">Habitica</a> as a way to help myself build daily habits and get through my todo list. It’s been working surprisingly—I’d even say embarrassingly—well. Progression systems and magic pixels, man. The part of me that fed a good chunk of my 20s into World of Warcraft is rolling its eyes in not-surprise.</p>

<p>Prior to doggo adoption, I’d gotten a pretty good streak of spending 20 minutes a day working on whatever my current project is… but found myself having a hard of time actually sitting down and writing about it. I think part of the friction here is how this blog is structured. Aside from a couple about-me pages, it’s a collection of articles. Trying to push my intended log-of-learning writing into this format has wound up making me feel like each entry needs to have a focused point and something to teach others. What I want out of this writing, instead, is just a nudge towards spending time deliberately learning and a bit of the clarity that comes from having to structure my thoughts to write them down. So, I’m going to try splitting this blog into two sections: a collection of articles/essays (which is most of the existing stuff) and a looser stream of thoughts and updates. Should be an interesting experiment to see if it helps shake loose writing more frequently.</p>


      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-04-19-resisting-an-avengers-joke/" rel="bookmark" title="The Elements Of Computing Systems: Resisting An Avengers Joke"> 
          <span class="post-date">Apr 19, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Out of the wiring swamp, on to the <a href="https://plus.google.com/+JeanBaptisteQueru/posts/dfydM2Cnepe">dizzying but invisible depths</a> of software abstraction.</p>

<p>I was actually a little surprised that there was a full chapter devoted to writing an assembler—it’s just mechanically translating assembly code to machine code, word for word, right? As it turns out, while command translation itself is super straightforward, location labels for branching and variable declaration added a little fun. We wound up with a two pass design: a first pas to allow for memory address allocation for each variable and label, then a second pass to generate the machine code itself.</p>

<p>The system isn’t self hosting—that is, we now don’t use the tools we’re writing to directly build the next level of software (which would laborious, since we haven’t built an operating system yet, much less a text editor!). This means we get to use whatever outside-of-Hack language we want to build the assembler. So now instead of fighting with HDL, I’m writing Ruby! I write Ruby most of the day for work and have for the last seven years or so.  It’s DARN NICE for text chomping.</p>

<p>Onwards!</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-04-09-hardware-complete/" rel="bookmark" title="The Elements of Computing Systems: Hardware, Complete"> 
          <span class="post-date">Apr 09, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Holy crap, we’re done with the hardware part. I built a computer!</p>

<h2 id="chapter-4">Chapter 4</h2>
<p>A cool aspect of each chapter’s material being a self-contained abstraction is that the book can skip between levels for pedagogical reasons. So we wound up learning to write some programs in the machine language for our fully-built computer, before the final phase of actually wiring up the complete computer.</p>

<p><a href="/images/assembly.png"><img src="/images/assembly.png" alt="hack assembly language" /></a></p>

<p>It’s… definitely for machines. Messing around with the assembly language was pretty important for the next chapter. Without that experience, I don’t think I’d have understood enough of the intent behind how things are accomplished using its limited idioms. Debugging when my CPU wasn’t wired up correctly might have cost me a fair bit more hair!</p>

<p>Two side notes from spelunking with Hack assembly:</p>

<ul>
  <li><a href="http://www.marksmath.com/tecs/hack-asm/hack-asm.html">This page</a> was a super useful companion for dealing with some very picky language stuff.</li>
  <li>There’s a part where you need to load a 16-bit word that’s all <code class="highlighter-rouge">1</code>s into memory to turn a part of the screen dark. You can actually only load 15-bit words in A-instructions, but the assembler will silently accept constants that are over the size you can express in 15 bits, leading to some serious headscratching.</li>
</ul>

<h2 id="chapter-5">Chapter 5</h2>
<p>Building the CPU and Memory units were the most challenging bits of HDL wiring so far. Breaking everything that needed to happen down into discrete tasks (and being well rested) was key here. Definitely went back to pen &amp; paper here to make this work.</p>

<p><a href="/images/cpu.jpg"><img src="/images/cpu.jpg" alt="wiring the CPU on paper" /></a></p>

<p>All that wiring gore boiled down to only 18 lines of HDL to make a simple CPU, using all of the previously built components. Wow.</p>

<p>I did lots of breaking inputs down into binary to make sense of how to connect logical wires. Plotting numbers out as monospaced binary is another useful form of sketching:</p>

<p><a href="/images/ram-binary.png"><img src="/images/ram-binary.png" alt="writing out RAM addresses in binary" /></a></p>

<p>An added level of difficult: bus indexing works backwards from how my brain thinks, as traditional array indexes go left to right. Bus indexing, on the other hand, goes from the least significant bit to the most signicant bit… which is right to left when binary is written out. This must have accounted for at least half the bugs I created.</p>

<h2 id="meta">Meta</h2>
<p>It’s been three weeks since the entry before this; not exactly the pace I set out for myself at the beginning of the year. I was getting a little bored with writing a single entry for each chapter, but trying to get two chapters worth of work done in a single week <em>and</em> a write up wound up taking much longer.</p>

<p>I’ve also been having a hard time finding the focus to do this particular project after work, so only the real progress happens on weekends. I figured that going back to the blinking lights part of programming would stretch different brain muscles from what I’m using at work, but I think that’s demonstrably false. I’m still having fun, but probably need to either moderate my expectations of what I can do during the week, and/or get more ok with these writeups being progress updates rather than proof of commpleting milestones.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-03-18-time-state-and-memory/" rel="bookmark" title="The Elements Of Computing Systems: Time, State & Memory"> 
          <span class="post-date">Mar 18, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Oh boy, a clock! In this chapter of <a href="http://www.nand2tetris.org/">nand2tetris</a>, we started teaching our logic circuits about time and consequently, memory. We’re introduced to a single new primitive, a data flipflop: all it does is output the value of its input one clock tick ago. With that and the array of combinatorial logic gates from previous chapters, we build all the way up to 16 kilobye RAM chips!</p>

<p>It was a bit disappointing that DFFs are given as primitives here. Though the book says they can be composed from Nand gates just like the rest of the chips we’ve built so far, it would have been neat to see the gory details of how one goes from combinatorial, stateless logic to sequential, time-based logic. Apparently the construction of DFFs is “intricate”, so I get pedagogically why we aren’t asked to implement them. Still, nandandflipflop2tetris just doesn’t have the same ring…</p>

<p>That aside, building memory chips felt like like bit twiddling and more like combining of logical components. These chips were easier to get right on the first-ish try without pen and paper; the composing of larger and larger RAM chips felt particularly simple and elegant. It did, however, take a bit for me to shift my thinking abouts values throughout a system being phased time-wise: e.g. you set inputs up, then <em>on the next clock tick</em> the outputs react.</p>

<p>Aside: an HDL syntax thing that I didn’t know is that you can declare pin connection twice on the gate. Like, if I wanted to hook up a DFF’s output pin to both the chip’s out pin and something else internally, you can do  <code class="highlighter-rouge">DFF(in=something, out=outb, out=out)</code> . The simulator won’t let you connect pins that touch the outside world to internal pins, so you can’t just use <code class="highlighter-rouge">out</code>. Go figure.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-03-12-teaching-sand-math/" rel="bookmark" title="The Elements Of Computing Systems: Teaching First-Grade Math To Virtual Sand"> 
          <span class="post-date">Mar 12, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Continuing my slow plod through TEoCS (also known as <a href="http://www.nand2tetris.org/">nand2tetris</a>), I’ve now reached the part of building in building a computer where I’ve built something that… computes.</p>

<p>The <em>Arithmetic Logic Unit</em> chip is the first thing I’ve made that felt like it deserved the label “chip” instead of the mechanical-sounding “gate”.  Just like everything else so far, at its heart it’s a bunch Nand gates with a lot of wires running between them… but it feels like we’ve crossed over from simple logic reified by wires into the real start of a more general purpose computing machine. The chip has a pair of 16-bit inputs, and 6 control bits, which you manipulate to do various combinations of arithmatic, from producing a constant value, addition, subtraction, bitwise boolean operations, negation upon those inputs. We’ll apparently be implementing multiplication and division at a higher level up the stack, but that’s a still a lot for some jumped-up simulated silicon.</p>

<p>It was, remarkably, only 14 lines of HDL code to implement, using all the gates I’d built so far.</p>

<p>It would have been pretty easy to rip through this chapter and build the ALU by just blindly implementing the logical operations indicated in the chip’s truth table and control bits, but I wanted to take a step back and work out with pen and paper <em>how</em> the chip actually accomplished a bunch of this math. It wasn’t obvious at all to me that, “ok, negate the y bus’s bits, then add them to x and then negate the result of that” comes out to <code class="highlighter-rouge">x-y</code>. But it does, and I’ve at least moved past taking it on faith after working out a few of these operations out with ink and dead trees. Pretty elegant design!</p>

<p>A few tidbits that were helpful for me as I worked through this chapter:</p>

<ul>
  <li>
    <p>You can use the literal values <code class="highlighter-rouge">true</code> or <code class="highlighter-rouge">false</code> if you want a wired to be always on or off.  This eluded me for a bit (heh heh heh).</p>
  </li>
  <li>
    <p>The tests will produce a (relatively) easy to read output file as they go. At least on OS X, it’s difficult to see the entirety of this output in the simulator’s UI, but it’s also available in a file in the current project directory with the <code class="highlighter-rouge">.out</code> extension. You can eyeball or diff each of its lines versus the test script’s <code class="highlighter-rouge">.cmp</code> file to start seeing where things have gone wrong.</p>
  </li>
  <li>
    <p>Examining the state of each internal pin of the chip in the hardware simulator is a great debugging technique. I found plenty of bugs by just running the test script, waiting for it to fail on a particular case, then stepping through what each internal pin/bus’s value should have been on paper.</p>
  </li>
</ul>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-02-22-blinking-lights/" rel="bookmark" title="The Elements of Computing Systems: Putting The Blinking Lights Back In Computer Science"> 
          <span class="post-date">Feb 22, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Last week, I cracked open <a href="http://www.nand2tetris.org/">The Elements of Computing Systems</a> and started working through it. It’s a book with a pretty cool idea: it walks you through thirteen projects that all build upon each other to create a complete general-purpose computer. The first chapter starts with transistors and logic gates; the last has Tetris running on an operating system you wrote!</p>

<p>My posts about work towards this year’s learning-and-doing goal have thus far been either been documenting a finished project or showcasing immediately usable tips and tricks. Working my way through this book is going to be a little different. I want to document my progress—hopefully without these posts sounding like a third-grade book report—so I’m just going to try and call out what was fun or interesting about the material as I work through it. Maybe a work journal like this will be a useful template for how to write about other longer, ongoing projects, but we’ll see! This is all serving as a proxy for habit changes, which is the most important thing to me.</p>

<hr />

<p>The first chapter of TEoCS has you building primitive boolean logic gates starting with just a single atom: a <a href="https://en.wikipedia.org/wiki/NAND_gate">Nand gate</a>. You progressively build more and more complicated gates, from the familiar Not/Or/And operators to stuff like multiplexors and n-way version of the earlier gates.</p>

<p>The book doesn’t come with a soldering iron, so this is all wired up inside a hardware simulator program (that reminds me of being introduced to pointers machine-language first in <a href="https://www.cs.oberlin.edu/~jdonalds/210/syllabus.html">CS210</a>). You wire up the gates by writing code in Hardware Definition Language: basically virtually naming all the chips and how wires connect them.  You can load into the simulator, and then change the value of various wires and see what happens. It’s a baroque-looking program, but pretty useful for exploring and debugging:</p>

<p><a href="/images/xor.png"><img src="/images/xor.png" alt="hardware simulator" /></a></p>

<p>Delightfully, the material has a set of test scripts that you can use to put your gates through their paces and make sure you’ve wired up everything correctly.</p>

<p>Creating gates like this via code definitely stretched my brain. Sketching them out on pen and paper was was really helpful:</p>

<p><a href="/images/circuit-sketch.jpg"><img src="/images/circuit-sketch.jpg" alt="circuit sketch" /></a></p>

<p>Next week, we teach the circuits to do math!</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2018-01-20-interlude-vacation/" rel="bookmark" title="Interlude - Vacation"> 
          <span class="post-date">Jan 20, 2018</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Though I’m generally terrible at taking regular vacations, last week my wife and I got away to Hawaii for some long overdue R&amp;R. We saw whales at sunset, stood 10 feet away from active lava flows, hiked an extinct volcano caldera, relaxed on the beach, and drank a whole bunch of rum drinks.</p>

<p>Regular learning posts resume next!</p>

<p><img src="/images/hawaii/beach-sunset.jpg" alt="Beach sunset" /></p>

<p><img src="/images/hawaii/botantical-garden-shore.jpg" alt="Botantical garden shore" /></p>

<p><img src="/images/hawaii/caldera.jpg" alt="Caldera floor" /></p>

<p><img src="/images/hawaii/hanu.jpg" alt="Sea turtle" /></p>

<p><img src="/images/hawaii/lava.jpg" alt="Lava!" /></p>

<p>Oh, and we got to experience about 38 minutes of sheer mortal terror.</p>

<p><img src="/images/hawaii/oh-fuck.png" alt="Missle alert" /></p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-07-23-notes-on-haskell-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Haskell: Seven Languages In Seven Weeks"> 
          <span class="post-date">Jul 23, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>I’ll admit I approached Haskell with a bit of trepidation: the language has a tongue-in-cheek unofficial motto of “avoid success at all costs” and a reputation of only being used by academic ivory-tower types.</p>

<h3 id="functional-strength">Functional Strength</h3>

<p>Haskell’s functional programming model is pure as the driven snow: unlike some of the functional languages earlier in the book, there’s no mutatable state whatsoever. Period, end of story. Like all the previous functional languages, lists of data are a first-class primitive and there are a number of tools for slicing and dicing them. The usual map/filter/fold suspects are around, as are succinct form for defining anonymous functions and some powerful list comprehension forms.</p>

<p>Lazy evaluation seems to be the default mode in Haskell. Under the hood, every function has a single argument—functions with multiple arguments are split into multiple functions that are then applied to each other. This allows for easy currying—saving functions with partially bound arguments for later full evaluation. These partially applied functions let you do some pretty nifty tricks, like incrementing a list via <code class="highlighter-rouge">map (+ 1) [1, 2, 3]</code>. Lazy evaluation also allows functions to be infinite generators without any special invocation or magic.</p>

<h3 id="not-my-type">Not My Type</h3>

<p>Haskell, while strongly typed, requires surprisingly little type declaration—the type checker can infer much of what it needs from the structure of the code. You can define your own types quite easily, both in terms of other types and recursively. These recursive definitions can lead to some very terse expressions of complex concepts - a one-line tree type definition, for example.</p>

<p>After all that, I have to admit that I don’t totally grok Haskell’s type system. Fighting with type error messages in GHC is what prevented me from doing most of the non-trivial exercises in this chapter. It’s apparent that once you learn to use it well, Haskell’s type system is sophisticated and very powerful—but for me, the learning curve proved greater than my enthusiasm for the language. Perhaps I’m spoiled by more dynamically-typed languages.</p>

<h3 id="monads-or-what-is-this-i-dont-even">Monads (Or, What Is This I Don’t Even)</h3>

<p>The book attempts to explain monads initially through an example involving drunken pirates, which is a perfectly good stand-in for my mental state while trying understand how monads work. The idea—I think—is a generally applicable way to represent state in a language that has no mutatable state. Monads seem to act as functions whose return values can work as state accumulators when chained together. Using monads under the covers, the <code class="highlighter-rouge">do</code> statement lets you write imperative looking code, but it’s actually chained together with monads and winds up boiling down to one big function invocation. That top-level conceptual understanding is where I stopped—exactly how to implement and practically use a monad was still a mystery to me after a section’s worth of examples.</p>

<h3 id="thanks-for-all-the-lambdas">Thanks For All The Lambdas</h3>

<p>At the end of this chapter, my trepidation unfortunately seemed justified. Perhaps it was a bit of new language burn-out or perhaps it was Haskell’s vertical learning curve, but I had a hell of a time getting as much out of Haskell as I did out of the other languages the book covered.  Frustration with Haskell aside, I had a blast with <em>Seven Languages In Seven Weeks</em>. Covering big swaths of intellectual territory is always fun, and I’ve got a non-trivial desire to start a deep dive into Clojure soon. Time to get back to building things.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-07-15-notes-on-clojure-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Clojure: Seven Languages In Seven Weeks"> 
          <span class="post-date">Jul 15, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>I’ve been looking forward to digging into Clojure ever since I saw Rich Hickey’s <a href="http://www.confreaks.com/videos/860-railsconf2012-keynote-simplicity-matters">keynote at RailsConf2012</a>. I’m still chewing on some of the philosophy Rich introduces in that talk, and wanting to seeing his approach to language design was a big part of why I picked up <em>Seven Languages In Seven Weeks</em> in the first place. Plus, I haven’t had the chance to mess around with a Lisp since that semester in college of finding myself in the empty list…</p>

<h3 id="basics">Basics</h3>

<p>Clojure is a Lisp dialect that runs on the JVM, with data and code alike represented in lists. The oft-quoted complaint about “Lisp parenthesis soup” is helped by syntactic suger for Clojure’s basic collection types: associative maps are denoted with <code class="highlighter-rouge">{}</code>s, sets use <code class="highlighter-rouge">#{}</code> and vectors have<code class="highlighter-rouge">[]</code>s. Even in just a couple days with the language, the parenthesis just become a form of whitespace when visually scanning properly indented Clojure.</p>

<p>These basic data structures in Clojure feel very well thought out, with Sequences serving as a common abstraction over most collections. Sequences are simply anything that implements the following interface: get the first element, get the rest of the sequence without the first element, and add an element to the front of the sequence (car, cdr, and cons for you Schemers playing along at home). Sequences can be lazy, allowing for some pretty powerful generator-like effects.</p>

<p>Clojure’s tools for working with these sequences are great. The usual functional suspects are there: <code class="highlighter-rouge">map</code>, <code class="highlighter-rouge">foldl</code>, and <code class="highlighter-rouge">filter</code>, along with a terse form for anonymous functions. There’s also some new stuff: the <code class="highlighter-rouge">take</code> function grabs a finite number of elements from the front of a sequence- so given a lazy sequence computing the fibonacci numbers, you could get the first N with <code class="highlighter-rouge">(take N fibonaccis)</code>.  <code class="highlighter-rouge">interpose</code> works like Ruby’s <code class="highlighter-rouge">join</code>, but works on and returns a sequence, so can be chained with other operations. Clojure also sports one of the most powerful list comprehension forms I’ve seen, supporting an arbitrary number of clauses and filters, even acting over multiple collections.</p>

<h3 id="on-the-jvm">On the JVM</h3>

<p>Rather than attempt to remain platform agnostic, Clojure seems to embrace the JVM as its host environment. Just like Scala, native Java types make appearances all over the place, though without a great deal of friction. The book didn’t have the space to elaborate, but hinted at some pretty slick integration with native Java libraries. Beyond just existing code integration, Clojure gets to reap the man-centuries put into making the JVM fast, stable and possessed of one of the sophisticated garbage collectors out there.</p>

<p>Running on the JVM has its limitations. Without native support, Clojure has no tail recursion, although it provides a loop/recur construct for efficiently unrolling recursive calls.</p>

<p>Also interesting is that although Clojure binds itself tightly to the JVM, there are independent ports of the language to  <a href="https://github.com/clojure/clojurescript">Javascript</a>, <a href="https://github.com/halgari/clojure-py">Python</a>, <a href="https://github.com/schani/clojurec">C</a>, <a href="https://github.com/clojure/clojure-clr">.NET</a> and more…</p>

<h3 id="records-and-types-not-objects">Records and types, not objects</h3>

<p>Clojure eschews Java’s approach to object-oriented data modeling, particularly leaving behind the notion of class-based inheritance. Types are defined with <code class="highlighter-rouge">defrecord</code> and functions are grouped around types with <code class="highlighter-rouge">defprotocol</code>.  Types are immutable - instead of modifying a record in-place, you return a new, different copy. There’s an emphasis on just enough abstraction over the data; types behave like maps, so you can start with a simple associative data structure and just add more behavior when you need it.</p>

<p>Types can interact fully with other code on the JVM, although the implications of this are unclear to me. Can I pass Clojure records to other JVM languages and have their immutable semantics respected?</p>

<h3 id="concurrency">Concurrency</h3>

<p>Clojure’s functional approach and strong push for immutatable state were designed to aid writing concurrent programs. State mutations can <em>only</em> be done inside explict transactions that prevent concurrent modifications from attempting to muck with a value at once.  The <code class="highlighter-rouge">atom</code> construct provides some sugar for concurrency-safe changes on a single value.</p>

<p>There are a couple of different mechanics to actually executing code in parallel.  Agents can do asynchronous processing with the same thread-safe transactional access mechanics as atoms.  Reading a value from a reference, agent, or atom won’t lock or block - updated values are just flipped in transactionally. So you might get an out-of-date value, but never one in an inconsistent state. Futures are another option for concurrency: they evaluate asynchronously, but reading their value returned blocks until evaluation is finished.</p>

<h3 id="clojure-runs-deep">Clojure runs deep</h3>

<p>My brief tour of Clojure had me recalling the ‘oh, wow’ feeling I felt learning Python for the first time after a few years of Java and C++. Clojure’s got some powerful ideas that I’m going to be trying to wrap my head around for a while. There’s a fit-togetherness about the language that makes me want to dig into it further. This is the first language in <em>Seven Language In Seven Days</em> that made me go out and buy a book on it before I was even done with the chapter—I’ll be tucking into <a href="http://www.amazon.com/gp/product/1449394701">Clojure Programming</a> just as soon as I’m done with Haskell.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-07-01-notes-on-erlang-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Erlang: Seven Languages In Seven Weeks"> 
          <span class="post-date">Jul 01, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>Erlang’s syntax and semantics feel like modern Prolog. It’s another almost-purely functional language, with all immutable variables. Basic operations are done via pattern matching with free variables and list deconstruction that make it clear why Prolog came first in the book.  Erlang also shares Prolog’s bizarre-to-modern-eyes punctuation rules; I still haven’t quite figured out when a statement should be terminated with a comma, period or semi-colon.</p>

<h3 id="practical-prolog">Practical Prolog?</h3>
<p>Thankfully, actually <em>doing</em> anything in a functional manner felt a lot easier with Erlang than with Prolog. Erlang is dynamically typed and has anonymous functions, along with the usual raft of each/map/reduce-type helpers. There are also a couple of functional primitives I hadn’t seen before: <code class="highlighter-rouge">takewhile</code> and <code class="highlighter-rouge">dropwhile</code> select or drop the all of the first items from a list that match the passed function until the first item that doesn’t match. Most of these operations can be further simplified syntactically with list comprehensions that can take an arbitrary number of conditional or modifying clauses. Cool stuff.</p>

<p>Interestingly, there’s also native syntax for binary packing and unpacking, which I suppose makes sense if Erlang was developed for telephony systems.</p>

<h3 id="free-range-grass-fed-organic-systems">Free-Range, Grass-Fed Organic Systems</h3>
<p>Erlang’s whole raison d’être is building fault-tolerant distributed systems. Like Scala, the basic concurrency primitives in Erlang are actors: lightweight processes that share nothing between them and communicate by message passing. Erlang’s pattern matching works quite beautifully for interpreting and acting upon these passed messages. Message-passing itself is asynchronous, but it’s fairly simple to build services that can provide a synchronous, blocking interface to actors.</p>

<p>There’s a marked emphasis on dealing with failure (“let it crash”) instead of attempting to recover from errors.Building a process that monitors other processes and restarts them when they die is a matter of a couple lines of code. The book alludes to built-in mechanisms for setting up distributed servers, communicating between them, and even hot-swapping code in-process but doesn’t go into depth due to space constraints.</p>

<p>I’ve got admit that I enjoyed my brief tour of Erlang more than I thought I would, especially after how unenthusiastic I was about Prolog. I’m still not sure I’d reach for Erlang unless I’m building a system that I know will be massively multi-server from the get-go. The actor model for concurrency is elegant as hell—but a lot of other, more familiar-feeling languages have copied it.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-06-02-notes-on-scala-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Scala: Seven Languages In Seven Weeks"> 
          <span class="post-date">Jun 16, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>After Prolog’s brain-bending, it was a bit of a relief to tackle Scala and return to a more familiar general-purpose language with a C-descended syntax.</p>

<h3 id="java">Java++?</h3>

<p>Scala seems to be attempting, in many ways, to be a better Java. It runs on the JVM and interoperates with Java freely - you can literally mix and match Scala and Java files in a single project, with all the classes involved able to call into each other without any translation layer. Many of the design choices made seem to attempt to solve Java’s problems, while still remaining compatible:</p>

<ul>
  <li>Scala, like Java, is strongly and statically typed, but does away with much of the ceremony around type declaration. Types are often simply inferred by the compiler, with no need to declare them.</li>
  <li>Scala has Java’s classical object inheritance model, but there are syntactic shortcuts for many parts of the system. Stuff like: constructors with no parameters can just be expressed as bare code after the class definition line, and short functions can be expressed on one line.</li>
  <li>Class methods and interfaces are present in Scala, but are actually separated out more cleanly into companion object declarations. Things defined with the <code class="highlighter-rouge">Object</code> keyword are straight-up class method structs, but <code class="highlighter-rouge">Trait</code>s actually behave more like Ruby mixins than Java interfaces.</li>
</ul>

<p>This level of improvement feels akin to CoffeeScript vs. Javascript: pretty great stuff, some nice improvements, but nothing that will affect the macro-level patterns one uses to write code or one’s overall productivity.</p>

<h3 id="lisp-y-behavior">LISP-y Behavior</h3>

<p>Here’s where Scala actually adds something to its Java roots: it supports real functional programming right alongside OOP. Scala has first-class, anonymous functions with lexical closures and a nice terse syntax for expressing them. Working with Scala’s collections will feel natural to Rubyists: you’ll find yourself happily mapping and folding along.</p>

<p>Scala’s concurrency model ties neatly into its functional nature. Rather than threads that share data and must deal with locking and concurrent access, Scala (like Io) uses asynchronous actors with no shared state These actors communicate via messages, the receiving of which can take advantage of some of the very powerful pattern matching at the core of the language These aren’t just case statements, but can do matching with conditional guards, regular expressions and even singleton types declared just for message-passing.</p>

<p>Scala’s typing model is clearly built to aid both concurrency and function programming - the choice of <code class="highlighter-rouge">val</code> vs. <code class="highlighter-rouge">var</code> when declaring a variable determines whether the variable is mutable or not. Given that immutability is so important for FP and parallel programming, that Scala has mutable variables at all feels like a compromise to interoperate with Java.</p>

<h3 id="friction">Friction</h3>

<p>Though Scala seems to be trying to do away with the syntactic bulk of Java (and the cognitive overhead associated with it), it certainly comes with its own set of baggage and ceremonies. For example, when extending a class via inheritance, you <em>must</em> use the <code class="highlighter-rouge">override</code> keyword anywhere the original classes signatures are overridden, even constructor parameters. Even at a syntax level, there’s a lot going on, even if it doesn’t contribute to lines-of-code-bloat like Java: a <code class="highlighter-rouge">&lt;-</code> here means dereference something enumerable in a loop and there a <code class="highlighter-rouge">-&gt;</code> means mapping a key to a value in Map creation shorthand. Types get odd at times as well: <code class="highlighter-rouge">Any</code> is everything’s superclass (ok) and <code class="highlighter-rouge">Nothing</code> is a subclass of everything (wat).</p>

<p>Then there’s the XML literals. I think it’s ultimately a gimmick: if you’re slicing and slicing a lot of XML files, having XPath querying built into your language can be nice, but do we really need support for this at a syntactic level? And because the web isn’t generally valid XML, using this for HTML screen-scraping is a non-starter. I just don’t get why this sort of thing isn’t a user-space library.</p>

<p>I’ve got mixed-to-negative feelings of Scala after this little first date with the language. If I were stuck on a big Java project and needed a better tool I could use without chucking the existing codebase, I might reach for Scala - but I’m not, and the language does doesn’t hang together well enough for me to consider putting a lot of time into learning more about it.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-05-24-notes-on-prolog-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Prolog: Seven Languages in Seven Weeks"> 
          <span class="post-date">May 24, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>A quick note on setup: on OS X Lion, I had to install GNU Prolog with <code class="highlighter-rouge">brew install gnu-prolog --use-gcc</code> to avoid compilation errors when using Clang.</p>

<p>Let’s get this out of the way: Prolog is not a general purpose language. It has its niche and can do some pretty interesting stuff inside that domain, but it’s not exactly suited for talking over a network or processing XML. Instead, Prolog is a declarative logic engine: you feed it knowledge and rules, then given these facts and constraints, it can be used to solve for values that fit your world of truth. You can prove statements true or false (“is a cat a mammal?”) or find missing pieces to make true statements (“I need yeast, barley, water and what else to make beer? Solve for what else.”).</p>

<p>Most of Prolog’s power seems to come from defining recursive rules that operate on lists of data. You can split apart lists with the <code class="highlighter-rouge">[Head|Tail]</code> syntax that reminds me of messing with lists in Lisp recursively with <code class="highlighter-rouge">car</code>/<code class="highlighter-rouge">cdr</code>. Problem solving using this approach feels very much like when I used to mess around with Scheme in college, but the process of unification—making symbols on both sides of rule agree— was hard to wrap my head around. For example, rather than saying something like <code class="highlighter-rouge">result = sum([1, 2, 3])</code>, you’d say <code class="highlighter-rouge">sum([1, 2, 3], Result).</code>, with Prolog supplying the value for unbound variable <code class="highlighter-rouge">Result</code> that would make it equal the sum of 1, 2 and 3. I would up doing a lot more thinking than typing when working through the problem sets.</p>

<p>I’ll be honest: Prolog was pretty unexciting to me, and I couldn’t muster up a lot of enthusiasm to work through the example problems. Writing a 27-line sudoku solver by just defining the rules of sudoku is pretty cool and all- but it’s a long leap from there to actually solving someone’s problems in the real world. A more practical example the book gives is a scheduling problem- given a set of scientists with varying schedules and given a laboratory with equipment they need to share, find a schedule that will fit all of them. Parsing languages according to a grammar seems like another interesting application, as do some forms of AI decision-making. All the same, I can’t see myself investing a lot of time in learning more about Prolog until I’ve got a Prolog-shaped problem in my daily work.</p>

      </div>
    </article>
  
    <article itemscope itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
      <h2 itemprop="headline">
        <a href="http://localhost:4000/logbooks/2012-05-20-notes-on-io-seven-languages-in-seven-weeks/" rel="bookmark" title="Notes on Io: Seven Languages In Seven Weeks"> 
          <span class="post-date">May 20, 2012</span>
        </a>
      </h2>
      <div class="article-wrap" itemprop="text">
        <p>I realized recently that though I’d learned a number of new technologies over the last few years, it had been far too long since I learned a new language. I picked up Bruce Tate’s <a href="http://pragprog.com/book/btlang/seven-languages-in-seven-weeks">Seven Languages In Seven Weeks</a> a month ago to remedy this, and wanted to jot down some notes as I went on my Magical Mystery Tour of programming languages.</p>

<p>Quick aside: The books starts with Ruby. I’ve been writing Ruby on and off since 2007, and professionally with Rails for the last year, so I have a reasonable grasp on the language already. I didn’t do the exercises, but was impressed with the author’s approach. Each language is split into three days- Ruby’s chapter goes very quickly from syntax and type system basics all the way down to Ruby’s flavor of metaprogramming. Relative newcomers to Ruby (especially in the Rails world) would do well to work through this chapter- you might just come away with a much better understand of how all that Rails magic actually works.</p>

<p>On to Io.</p>

<h2 id="what-moving-parts">What Moving Parts?</h2>

<p>Io’s core syntax is the simplest thing this side of Scheme. All the hard rules are contained in a scant few pages of this chapter. Everything else is malleable to a pretty ludicrous degree.</p>

<p>Everything in Io is an object; objects, in turn, are just sets of named slots. Slots can contain either methods or data. All interaction is done via message-passing: <code class="highlighter-rouge">Foo bar</code> sends the message <code class="highlighter-rouge">bar</code> to object <code class="highlighter-rouge">Foo</code> - either returning the data in slot <code class="highlighter-rouge">bar</code> on <code class="highlighter-rouge">Foo</code> or calling the method <code class="highlighter-rouge">bar</code> on <code class="highlighter-rouge">Foo</code>, depending on what’s in the slot.</p>

<p>Io, like Javascript, is prototype based. You clone existing objects rather than instantiating new ones from class templates. Messages are passed up the prototype chain to the object’s parent if the object itself doesn’t know how to handle the message. If you’re fuzzy on prototype-based inheritance in Javascript, read this chapter. It’ll help even if you’re using a library or transpiled JS language that mocks class-based inheritance for you.</p>

<p>Interestingly, types in Io are just themselves objects. Creating an object with a lowercase name gives the resulting object a <code class="highlighter-rouge">type</code> slot with a reference to the cloned object; objects with uppercase names don’t get this <code class="highlighter-rouge">type</code> slot and get treated as types by convention only. Cloning <code class="highlighter-rouge">Meat</code> from <code class="highlighter-rouge">Food</code> would create an object you’d likely use as a type, but cloning <code class="highlighter-rouge">bacon</code> from <code class="highlighter-rouge">Meat</code> would simply give you an object with a type of <code class="highlighter-rouge">Meat</code>.</p>

<h2 id="bending-reality">Bending Reality</h2>

<p>And you thought Ruby was great for making DSLs? Io lets you redefine and extend everything from the built-in operator table to the semantics of message-passing between objects. Everything is open for reflection - I’m used to object level reflection from Ruby et al, but the message level reflection that lets you get the target and sender of the message inside the call was new and cool.</p>

<p>The last section of this chapter takes you through defining a JSON-ish syntax for map literals and a lispy-looking way to define XML tags, each in around 20 lines of code. It’s pretty indicative of what you can do with the language that I managed to break vim-io’s syntax highlighting with completely valid, executable code while working on these examples.</p>

<p>I’m honestly a bit wary of all this. I’ve seen beautiful APIs created by metaprogramming in Ruby, but I’ve also seen my fair share of coding horrors done with the same. I’d like to be able to rely on at least some common rules when using someone else’s code and not worry that it’s just subtly altered the environment everything else runs in.</p>

<h2 id="all-at-once">All At Once</h2>

<p>Io’s concurrency features are slick as hell. There’s no preemptive multitasking here - no locks, no threads, no worries about concurrent state-modification. Everything is done through user-level cooperative coroutines.</p>

<p>The mechanics of using coroutines are as simple as the language’s syntax. Any message can be converted to an asynchronous actor by prefixing it with @@. The message passing then returns nil and the execution of the method goes on in the background: <code class="highlighter-rouge">blender liquify</code> can be converted to a background job by just changing it to <code class="highlighter-rouge">blender @@liquify</code>. A coroutine can call <code class="highlighter-rouge">yield</code> to voluntarily give control back to another coroutine- useful for running two jobs in parallel with interdependent steps.</p>

<p>Prepending a single @ to a message returns a future instead of nil. You can store the future and go about your business while the object in question does its async business out of band. When the caller needs the result, they pass messages to the future as though its result had already returned. If the result is ready, everything proceeds as normal; otherwise, the current coroutine blocks until the future returns. Apparently there’s also automatic deadlock detection - Io will automatically raise an exception if one is detected instead of hanging.</p>

<p>I really like the idea of futures for the low-hanging fruit involved in something like rendering a page that needs 5 database queries worth of data. Each query is independent of the others, so you just kick them off in the background, grab the futures returned and start your rendering, accessing the future-query results as needed. You’re still bound by the length of the longest query, but there’s no reason to wait for the preceding one to return before calling the next.</p>

<p>Up next, Prolog. At this rate, it’s going to be “Seven Languages in Seven Months”. But I’m having fun.</p>

      </div>
    </article>
  
</div><!-- /#index -->

<div class="footer-wrap">
  <footer>
    <span>&copy; 2018 Thomas Mayfield. Powered by <a href="http://jekyllrb.com">Jekyll</a> using the <a href="http://mademistakes.com/">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
         })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-28952322-1', 'thegreata.pe');
  ga('send', 'pageview');

</script>


</body>
</html>
